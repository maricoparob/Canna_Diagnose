{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPmgLU0PUbjW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "\n",
        "def create_folder():\n",
        "    \"\"\"\n",
        "    Create a new folder with a timestamp as its name in the current working directory.\n",
        "    Returns the path to the newly created folder.\n",
        "    \"\"\"\n",
        "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    folder_path = os.path.join(os.getcwd(), timestamp)\n",
        "    os.makedirs(folder_path, exist_ok=True)\n",
        "    return folder_path\n",
        "\n",
        "\n",
        "def move_images(images_list, folder_path):\n",
        "    \"\"\"\n",
        "    Move a list of images to the specified folder.\n",
        "    :param images_list: List of image file paths to move\n",
        "    :param folder_path: Path to the folder where images will be moved\n",
        "    \"\"\"\n",
        "    for img_path in images_list:\n",
        "        img_name = os.path.basename(img_path)\n",
        "        new_path = os.path.join(folder_path, img_name)\n",
        "        os.replace(img_path, new_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "from utils import create_folder, move_images\n",
        "\n",
        "# Assume you have a list of image file paths called `images`\n",
        "new_folder = create_folder()\n",
        "move_images(images, new_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "1_Vy5zwIU_VH",
        "outputId": "5845bdc7-3daf-4f3b-da2f-9d518b490405"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-379f34d3fe81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove_images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Assume you have a list of image file paths called `images`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnew_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qYK3qt5V2Sb",
        "outputId": "ebfe8359-0a29-4a31-a2dc-1c559c4ad174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import cv2\n",
        "# import numpy as np\n",
        "\n",
        "# # Create a folder to store the output images\n",
        "# if not os.path.exists('/content/drive/MyDrive/cannabis_mar3/output_images'):\n",
        "#     os.makedirs('/content/drive/MyDrive/cannabis_mar3/output_images')\n",
        "\n",
        "# # Load the input image\n",
        "# # img = cv2.imread('input_image.jpg')\n",
        "# img = cv2.imread(f'/content/drive/MyDrive/cannabis/cannabis-7.png')\n",
        "\n",
        "# # Define the range of blur kernel sizes, blur types, and threshold values to iterate over\n",
        "# kernel_sizes = [3, 5, 7]\n",
        "# blur_types = ['gaussian', 'median']\n",
        "# threshold_values = [100, 150, 200]\n",
        "\n",
        "# # Define the output file path\n",
        "# output_file_path = 'contours_results.txt'\n",
        "\n",
        "# # Open the output file in append mode\n",
        "# with open(output_file_path, 'a') as f:\n",
        "#     f.write('kernel_size,blur_type,threshold_value,contours_count\\n')\n",
        "\n",
        "# # Iterate over different blur kernel sizes, blur types, and threshold values\n",
        "# for kernel_size in kernel_sizes:\n",
        "#     for blur_type in blur_types:\n",
        "#         for threshold_value in threshold_values:\n",
        "            \n",
        "#             # Apply blur\n",
        "#             if blur_type == 'gaussian':\n",
        "#                 img_blur = cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
        "#             elif blur_type == 'median':\n",
        "#                 img_blur = cv2.medianBlur(img, kernel_size)\n",
        "                \n",
        "#             # Apply thresholding\n",
        "#             img_gray = cv2.cvtColor(img_blur, cv2.COLOR_BGR2GRAY)\n",
        "#             ret, img_thresh = cv2.threshold(img_gray, threshold_value, 255, cv2.THRESH_BINARY)\n",
        "            \n",
        "#             # Find contours\n",
        "#             contours, hierarchy = cv2.findContours(img_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "#             contours_count = len(contours)\n",
        "            \n",
        "#             # Write the results to the output file\n",
        "#             with open(output_file_path, 'a') as f:\n",
        "#                 f.write(f'{kernel_size},{blur_type},{threshold_value},{contours_count}\\n')\n"
      ],
      "metadata": {
        "id": "XHGRBhSiVBgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Create a folder to store the output images\n",
        "if not os.path.exists('/content/drive/MyDrive/cannabis_classifier/output_images'):\n",
        "    os.makedirs('/content/drive/MyDrive/cannabis_classifier/output_images')\n",
        "\n",
        "# Load the input image\n",
        "img = cv2.imread(f'/content/drive/MyDrive/cannabis/cannabis-7.png')\n",
        "\n",
        "# Define the range of blur kernel sizes, blur types, and threshold values to iterate over\n",
        "kernel_sizes = [3, 5, 7]\n",
        "blur_types = ['gaussian', 'median']\n",
        "threshold_values = [100, 150, 200]\n",
        "\n",
        "# Open the output file in append mode\n",
        "with open('output.csv', 'a') as f:\n",
        "    f.write('kernel_size,blur_type,threshold_value,contours_count\\n')\n",
        "\n",
        "# Iterate over different blur kernel sizes, blur types, and threshold values\n",
        "for kernel_size in kernel_sizes:\n",
        "    for blur_type in blur_types:\n",
        "        for threshold_value in threshold_values:\n",
        "            \n",
        "            # Apply blur\n",
        "            if blur_type == 'gaussian':\n",
        "                img_blur = cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
        "            elif blur_type == 'median':\n",
        "                img_blur = cv2.medianBlur(img, kernel_size)\n",
        "                \n",
        "            # Apply thresholding\n",
        "            img_gray = cv2.cvtColor(img_blur, cv2.COLOR_BGR2GRAY)\n",
        "            ret, img_thresh = cv2.threshold(img_gray, threshold_value, 255, cv2.THRESH_BINARY)\n",
        "            \n",
        "            # Find contours\n",
        "            contours, hierarchy = cv2.findContours(img_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "            contours_count = len(contours)\n",
        "            \n",
        "            # Draw contours on a copy of the input image\n",
        "            img_contours = img.copy()\n",
        "            cv2.drawContours(img_contours, contours, -1, (0, 0, 255), 2)\n",
        "            \n",
        "            # Save the image to disk\n",
        "            output_image_path = f'/content/drive/MyDrive/cannabis_classifier/output_images/output_{kernel_size}_{blur_type}_{threshold_value}.jpg'\n",
        "            cv2.imwrite(output_image_path, img_contours)\n",
        "            \n",
        "            # Write the results to the output file\n",
        "            with open('output.csv', 'a') as f:\n",
        "                f.write(f'{kernel_size},{blur_type},{threshold_value},{contours_count}\\n')\n"
      ],
      "metadata": {
        "id": "zDNcg_BDZvY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# kernel_sizes = [3, 5, 7]\n",
        "# blur_types = ['gaussian', 'median']\n",
        "# threshold_values = [100, 150, 200]\n",
        "\n",
        "# # Define the range of blur kernel sizes, blur types, and threshold values to iterate over\n",
        "\n",
        "# # kernel_sizes = 1\n",
        "# # blur_types = ['gaussian', 'median']\n",
        "# # threshold_values = range(50, 250, 20)"
      ],
      "metadata": {
        "id": "J5u_Zf--VIn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total iterations = length(kernel_sizes) * length(blur_types) * length(threshold_values)\n",
        "                = 3 * 2 * 3\n",
        "                = 18\n"
      ],
      "metadata": {
        "id": "RaHvF9TuY8w6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# # Iterate over different blur kernel sizes, blur types, and threshold values\n",
        "# for kernel_size in kernel_sizes:\n",
        "#     for blur_type in blur_types:\n",
        "#         for threshold_value in threshold_values:\n",
        "            \n",
        "#             # Check that the kernel size is valid\n",
        "#             if kernel_size % 2 == 0 or kernel_size < 1:\n",
        "#                 print(f\"Invalid kernel size: {kernel_size}\")\n",
        "#                 continue\n",
        "            \n",
        "#             # Apply blur\n",
        "#             if blur_type == 'gaussian':\n",
        "#                 img_blur = cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
        "#             elif blur_type == 'median':\n",
        "#                 img_blur = cv2.medianBlur(img, kernel_size)\n",
        "                \n",
        "#             # Apply thresholding\n",
        "#             img_gray = cv2.cvtColor(img_blur, cv2.COLOR_BGR2GRAY)\n",
        "#             ret, img_thresh = cv2.threshold(img_gray, threshold_value, 255, cv2.THRESH_BINARY)\n",
        "            \n",
        "#             # Write the parameters to the output file\n",
        "#             with open(output_file_path, 'a') as f:\n",
        "#                 f.write(f'{kernel_size},{blur_type},{threshold_value}\\n')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "zlnegS1RVMCD",
        "outputId": "8b06c716-f6d7-4912-dc25-93bc2c6a0300"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-15c87ef83d49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m# Write the parameters to the output file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{kernel_size},{blur_type},{threshold_value}\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'output_file_path' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
        "# from tensorflow.keras.models import Model\n",
        "\n",
        "# def create_cnn(input_shape, num_classes):\n",
        "#     # Define the input layer\n",
        "#     inputs = Input(shape=input_shape)\n",
        "    \n",
        "#     # Add a series of convolutional and pooling layers\n",
        "#     x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
        "#     x = MaxPooling2D((2, 2))(x)\n",
        "#     x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "#     x = MaxPooling2D((2, 2))(x)\n",
        "#     x = Conv2D(128, (3, 3), activation='relu')(x)\n",
        "#     x = MaxPooling2D((2, 2))(x)\n",
        "    \n",
        "#     # Flatten the output from the convolutional layers\n",
        "#     x = Flatten()(x)\n",
        "    \n",
        "#     # Add a series of fully connected layers\n",
        "#     x = Dense(256, activation='relu')(x)\n",
        "#     x = Dense(128, activation='relu')(x)\n",
        "#     outputs = Dense(num_classes, activation='softmax')(x)\n",
        "    \n",
        "#     # Define the model\n",
        "#     model = Model(inputs=inputs, outputs=outputs)\n",
        "    \n",
        "#     return model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MSV--QD5VNEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# model.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "id": "3gZmgkM3VXJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss, accuracy = model.evaluate(x_test, y_test)\n",
        "# predictions = model.predict(x_test)\n"
      ],
      "metadata": {
        "id": "jU5T785dVXmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn import svm\n",
        "\n",
        "# # Load the dataset and extract features\n",
        "# X_train, y_train = load_data('train/')\n",
        "# X_test, y_test = load_data('test/')\n",
        "# X_train_features = extract_features(X_train)\n",
        "# X_test_features = extract_features(X_test)\n",
        "\n",
        "# # Train the SVM model\n",
        "# model = svm.SVC(kernel='linear', C=1, gamma='auto')\n",
        "# model.fit(X_train_features, y_train)\n",
        "\n",
        "# # Evaluate the model\n",
        "# accuracy = model.score(X_test_features, y_test)\n",
        "# print('Accuracy:', accuracy)\n",
        "\n",
        "# # Save the model\n",
        "# with open('svm_model.pkl', 'wb') as f:\n",
        "#     pickle.dump(model, f)\n"
      ],
      "metadata": {
        "id": "kkZRhlHXVZT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# # Load the dataset and extract features\n",
        "# X_train, y_train = load_data('train/')\n",
        "# X_test, y_test = load_data('test/')\n",
        "# X_train_features = extract_features(X_train)\n",
        "# X_test_features = extract_features(X_test)\n",
        "\n",
        "# # Train the random forest model\n",
        "# model = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
        "# model.fit(X_train_features, y_train)\n",
        "\n",
        "# # Evaluate the model\n",
        "# accuracy = model.score(X_test_features, y_test)\n",
        "# print('Accuracy:', accuracy)\n",
        "\n",
        "# # Save the model\n",
        "# with open('random_forest_model.pkl', 'wb') as f:\n",
        "#     pickle.dump(model, f)\n"
      ],
      "metadata": {
        "id": "sI4Q9B1CVdDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.applications import VGG16\n",
        "# from tensorflow.keras.layers import Input, Flatten, Dense\n",
        "# from tensorflow.keras.models import Model\n",
        "\n",
        "# # Load the dataset and preprocess the images\n",
        "# X_train, y_train = load_data('train/')\n",
        "# X_test, y_test = load_data('test/')\n",
        "# X_train_preprocessed = preprocess_images(X_train)\n",
        "# X_test_preprocessed = preprocess_images(X_test)\n",
        "\n",
        "# # Load the pre-trained VGG16 model\n",
        "# base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# # Freeze the layers in the base model\n",
        "# for layer in base_model.layers:\n",
        "#     layer.trainable = False\n",
        "\n",
        "# # Add new layers on top of the base model\n",
        "# inputs = Input(shape=(224, 224, 3))\n",
        "# x = base_model(inputs)\n",
        "# x = Flatten()(x)\n",
        "# x = Dense(256, activation='relu')(x)\n",
        "# x = Dense(128, activation='relu')(x)\n",
        "# outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# # Define the model\n",
        "# model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# # Train the model\n",
        "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# model.fit(X_train_preprocessed, y_train_categorical, epochs=10, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# # Evaluate the model\n",
        "\n",
        "# loss, accuracy = model.evaluate(X_test_preprocessed, y_test_categorical)\n",
        "# print('Accuracy:', accuracy)\n",
        "\n",
        "# # Save the model\n",
        "\n",
        "# model.save('cnn_model.h5')\n"
      ],
      "metadata": {
        "id": "bZHnnl-pVe1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "4. Feature-based methods\n",
        "\n",
        "Feature-based methods involve extracting features from images and using machine learning algorithms, such as k-nearest neighbors or decision trees, to classify them. Features can include color histograms, texture descriptors, or local binary patterns.\n"
      ],
      "metadata": {
        "id": "cxbjzHUuVlvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# from sklearn.neighbors import KNeighborsClassifier\n",
        "# from skimage.feature import hog\n",
        "\n",
        "# # Load the dataset and extract features\n",
        "# X_train, y_train = load_data('train/')\n",
        "# X_test, y_test = load_data('test/')\n",
        "# X_train_features = extract_hog_features(X_train)\n",
        "# X_test_features = extract_hog_features(X_test)\n",
        "\n",
        "# # Train the k-nearest neighbors model\n",
        "# model = KNeighborsClassifier(n_neighbors=5)\n",
        "# model.fit(X_train_features, y_train)\n",
        "\n",
        "# # Evaluate the model\n",
        "# accuracy = model.score(X_test_features, y_test)\n",
        "# print('Accuracy:', accuracy)\n",
        "\n",
        "# # Save the model\n",
        "# with open('knn_model.pkl', 'wb') as f:\n",
        "#     pickle.dump(model, f)\n"
      ],
      "metadata": {
        "id": "174fbTMfVhu9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}